{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "F0O3lRcGFOpK",
        "outputId": "4c99afe4-4e61-46d6-9909-7d0ee2f888cd"
      },
      "outputs": [],
      "source": [
        "#!pip install datasets==1.4.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "QMUKOpC6Jui_",
        "outputId": "66f4bade-5742-4d13-ecdf-77cdf9153bc6"
      },
      "outputs": [],
      "source": [
        "#!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIyG4YScJulc",
        "outputId": "301934c6-0fe6-49c0-e252-a182ce63ae58"
      },
      "outputs": [],
      "source": [
        "#!pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlzmvHmIJuoN",
        "outputId": "c333c9d6-074b-4e6d-93d1-3de184fa9bba"
      },
      "outputs": [],
      "source": [
        "#!python -m pip install -U nn_pruning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!sudo kill -9 30689"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFvKmPljFJwy",
        "outputId": "8d35643d-fee3-4231-d642-15c682b9ff0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using transformers v4.35.0 and datasets v1.4.1 and torch v2.1.0+cu121\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import datasets\n",
        "import transformers\n",
        "datasets.logging.set_verbosity_error()\n",
        "transformers.logging.set_verbosity_error()\n",
        "print(f\"Using transformers v{transformers.__version__} and datasets v{datasets.__version__} and torch v{torch.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWo5RBc9FJw0",
        "outputId": "6f59758e-c101-427a-e14d-4ff92b23b03b"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "sst = load_dataset(\"glue\", \"sst2\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDQRgXyiFJw0",
        "outputId": "0f20372f-ecf1-4393-94b1-31a9da602128"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'idx': 0,\n",
              " 'label': 0,\n",
              " 'sentence': 'hide new secretions from the parental units '}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sst['train'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfoePaCyFJw1",
        "outputId": "39d75c86-85a6-409e-9d7d-693226656810"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sentence', 'idx', 'labels'],\n",
              "        num_rows: 67349\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['sentence', 'idx', 'labels'],\n",
              "        num_rows: 872\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['sentence', 'idx', 'labels'],\n",
              "        num_rows: 1821\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sst.rename_column(\"label\", \"labels\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install --upgrade --quiet jupyter_client ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "O5tU4w4lFJw1"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "bert_ckpt = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(bert_ckpt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "l--secK5FJw2"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_encode(examples):\n",
        "    return tokenizer(examples['sentence'], truncation=\"only_second\")\n",
        "\n",
        "sst_enc = sst.map(tokenize_and_encode, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install nn_pruning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "abjwOd00FJw3"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "from nn_pruning.sparse_trainer import SparseTrainer\n",
        "\n",
        "class PruningTrainer(SparseTrainer, Trainer):\n",
        "    def __init__(self, sparse_args, *args, **kwargs):\n",
        "        Trainer.__init__(self, *args, **kwargs)\n",
        "        SparseTrainer.__init__(self, sparse_args)\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        \"\"\"\n",
        "        We override the default loss in SparseTrainer because it throws an\n",
        "        error when run without distillation\n",
        "        \"\"\"\n",
        "        outputs = model(**inputs)\n",
        "        if self.args.past_index >= 0:\n",
        "            self._past = outputs[self.args.past_index]\n",
        "        loss = outputs[\"loss\"] if isinstance(outputs, dict) else outputs[0]\n",
        "        self.metrics[\"ce_loss\"] += float(loss)\n",
        "        self.loss_counter += 1\n",
        "        return (loss, outputs) if return_outputs else loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "g3O9wdNNFJw5"
      },
      "outputs": [],
      "source": [
        "hyperparams = {\n",
        "    \"dense_pruning_method\": \"topK:1d_alt\",\n",
        "    \"attention_pruning_method\": \"topK\",\n",
        "    \"initial_threshold\": 1.0,\n",
        "    \"final_threshold\": 0.3,\n",
        "    \"initial_warmup\": 1,\n",
        "    \"final_warmup\": 3,\n",
        "    \"attention_block_rows\":32,\n",
        "    \"attention_block_cols\":32,\n",
        "    \"attention_output_with_dense\": 0\n",
        "}\n",
        "\n",
        "for k,v in hyperparams.items():\n",
        "    if hasattr(sparse_args, k):\n",
        "        setattr(sparse_args, k, v)\n",
        "    else:\n",
        "        print(f\"sparse_args does not have argument {k}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "BPI7xpfyFJw6"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "batch_size = 16\n",
        "learning_rate = 2e-5\n",
        "num_train_epochs = 6\n",
        "logging_steps = len(sst_enc[\"train\"]) // batch_size\n",
        "warmup_steps = logging_steps * num_train_epochs * 0.1\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"checkpoints\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    learning_rate=learning_rate,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=logging_steps,\n",
        "    save_strategy=\"epoch\",\n",
        "    disable_tqdm=False,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    report_to=None\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "BVD7J0bcFJw7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from nn_pruning.patch_coordinator import ModelPatchingCoordinator\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "mpc = ModelPatchingCoordinator(\n",
        "    sparse_args=sparse_args,\n",
        "    device=device,\n",
        "    cache_dir=\"checkpoints\",\n",
        "    logit_names=\"logits\",\n",
        "    teacher_constructor=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "PKGocDr_FJw8"
      },
      "outputs": [],
      "source": [
        "bert_model = AutoModelForSequenceClassification.from_pretrained(bert_ckpt).to(device)\n",
        "mpc.patch_model(bert_model)\n",
        "\n",
        "bert_model.save_pretrained(\"models/patched\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "LA6AdtV_FJw9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from datasets import load_metric\n",
        "\n",
        "accuracy_score = load_metric('accuracy')\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    predictions, labels = pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return accuracy_score.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "VuzyDBphFJw9"
      },
      "outputs": [],
      "source": [
        "trainer = PruningTrainer(\n",
        "    sparse_args=sparse_args,\n",
        "    args=args,\n",
        "    model=bert_model,\n",
        "    train_dataset=sst_enc[\"train\"],\n",
        "    eval_dataset=sst_enc[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ZH6qUoQyFJw9"
      },
      "outputs": [],
      "source": [
        "trainer.set_patch_coordinator(mpc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "p8GwLNOJFJw9",
        "outputId": "f4ebdd81-1f54-4f1d-d15e-e10e2af16843"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/.local/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25260' max='25260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25260/25260 1:36:57, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Samples Per Second</th>\n",
              "      <th>Steps Per Second</th>\n",
              "      <th>Threshold</th>\n",
              "      <th>Regu Lambda</th>\n",
              "      <th>Ampere Temperature</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.229500</td>\n",
              "      <td>0.680909</td>\n",
              "      <td>0.490826</td>\n",
              "      <td>7.035800</td>\n",
              "      <td>123.938000</td>\n",
              "      <td>7.817000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.159600</td>\n",
              "      <td>0.528196</td>\n",
              "      <td>0.775229</td>\n",
              "      <td>7.035300</td>\n",
              "      <td>123.947000</td>\n",
              "      <td>7.818000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.132000</td>\n",
              "      <td>0.416278</td>\n",
              "      <td>0.807339</td>\n",
              "      <td>7.047800</td>\n",
              "      <td>123.726000</td>\n",
              "      <td>7.804000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.115200</td>\n",
              "      <td>0.417619</td>\n",
              "      <td>0.879587</td>\n",
              "      <td>7.007800</td>\n",
              "      <td>124.433000</td>\n",
              "      <td>7.848000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.092400</td>\n",
              "      <td>0.481744</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>6.997000</td>\n",
              "      <td>124.624000</td>\n",
              "      <td>7.860000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.074200</td>\n",
              "      <td>0.524992</td>\n",
              "      <td>0.891055</td>\n",
              "      <td>7.039900</td>\n",
              "      <td>123.866000</td>\n",
              "      <td>7.813000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer.train();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "MfWZaDkgFJw-"
      },
      "outputs": [],
      "source": [
        "output_model_path = \"models/bert-base-uncased-finepruned-sst-30\"\n",
        "trainer.save_model(output_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "cIU7rtq9FJw-"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(9, 144)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mpc.compile_model(trainer.model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Yr_AVcrcFJw_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "removed heads 0, total_heads=135, percentage removed=0.0\n",
            "bert.encoder.layer.0.intermediate.dense, sparsity = 69.99\n",
            "bert.encoder.layer.0.output.dense, sparsity = 69.99\n",
            "bert.encoder.layer.1.intermediate.dense, sparsity = 69.99\n",
            "bert.encoder.layer.1.output.dense, sparsity = 69.99\n",
            "bert.encoder.layer.2.intermediate.dense, sparsity = 69.99\n",
            "bert.encoder.layer.2.output.dense, sparsity = 69.99\n",
            "bert.encoder.layer.3.intermediate.dense, sparsity = 69.99\n",
            "bert.encoder.layer.3.output.dense, sparsity = 69.99\n",
            "bert.encoder.layer.4.intermediate.dense, sparsity = 69.99\n",
            "bert.encoder.layer.4.output.dense, sparsity = 69.99\n",
            "bert.encoder.layer.5.intermediate.dense, sparsity = 69.99\n",
            "bert.encoder.layer.5.output.dense, sparsity = 69.99\n",
            "bert.encoder.layer.6.intermediate.dense, sparsity = 69.99\n",
            "bert.encoder.layer.6.output.dense, sparsity = 69.99\n",
            "bert.encoder.layer.7.intermediate.dense, sparsity = 69.99\n",
            "bert.encoder.layer.7.output.dense, sparsity = 69.99\n",
            "bert.encoder.layer.8.intermediate.dense, sparsity = 69.99\n",
            "bert.encoder.layer.8.output.dense, sparsity = 69.99\n",
            "bert.encoder.layer.9.intermediate.dense, sparsity = 69.99\n",
            "bert.encoder.layer.9.output.dense, sparsity = 69.99\n",
            "bert.encoder.layer.10.intermediate.dense, sparsity = 69.99\n",
            "bert.encoder.layer.10.output.dense, sparsity = 69.99\n",
            "bert.encoder.layer.11.intermediate.dense, sparsity = 69.99\n",
            "bert.encoder.layer.11.output.dense, sparsity = 69.99\n"
          ]
        }
      ],
      "source": [
        "from nn_pruning.inference_model_patcher import optimize_model\n",
        "\n",
        "prunebert_model = optimize_model(trainer.model, \"dense\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "68057978"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prunebert_model.num_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "107712578"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bert_model.num_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "001QJCBpFJw_"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6318480094311734"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prunebert_model.num_parameters() / bert_model.num_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "VYPA85cNFJw_"
      },
      "outputs": [],
      "source": [
        "from time import perf_counter\n",
        "\n",
        "def compute_latencies(model,\n",
        "                      sentence = \"\"\"swimming is above all about a young woman 's face , \n",
        "                      and by casting an actress whose face projects that woman 's doubts and yearnings , it succeeds .\"\"\"):\n",
        "    inputs = tokenizer(sentence, truncation=\"only_second\", return_tensors=\"pt\")\n",
        "    latencies = []\n",
        "\n",
        "    for _ in range(10):\n",
        "        _ = model(**inputs)\n",
        "\n",
        "    for _ in range(100):\n",
        "        start_time = perf_counter()\n",
        "        _ = model(**inputs)\n",
        "        latency = perf_counter() - start_time\n",
        "        latencies.append(latency)\n",
        "        time_avg_ms = 1000 * np.mean(latencies)\n",
        "        time_std_ms = 1000 * np.std(latencies)\n",
        "    print(f\"Average latency (ms) - {time_avg_ms:.2f} +\\- {time_std_ms:.2f}\")\n",
        "    return {\"time_avg_ms\": time_avg_ms, \"time_std_ms\": time_std_ms}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "i8vMxCmAFJw_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average latency (ms) - 33.67 +\\- 0.16\n"
          ]
        }
      ],
      "source": [
        "latencies = {}\n",
        "compute_latencies(prunebert_model.to(\"cpu\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "wTYSrpqyFJxA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average latency (ms) - 56.62 +\\- 0.13\n"
          ]
        }
      ],
      "source": [
        "bert_unpruned = AutoModelForSequenceClassification.from_pretrained(\"doyoungkim/bert-base-uncased-finetuned-sst2\").to(\"cpu\")\n",
        "compute_latencies(bert_unpruned.to(\"cpu\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#ref: https://github.com/huggingface/nn_pruning"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
